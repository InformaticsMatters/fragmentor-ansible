---
kind: Job
apiVersion: batch/v1
metadata:
  name: fragmentor-player
  namespace: {{ fc_namespace }}
spec:
  backoffLimit: 1
  template:
    metadata:
      labels:
        name: fragmentor-player
    spec:
      serviceAccountName: fragmentor

      # A 'required'
      # node selection affinity...
#      affinity:
#        nodeAffinity:
#          requiredDuringSchedulingIgnoredDuringExecution:
#            nodeSelectorTerms:
#            - matchExpressions:
#              - key: informaticsmatters.com/purpose
#                operator: In
#                values:
#                - fragmentor

      containers:
      - name: fragmentor-player
        image: {{ fc_image_registry }}/{{ fc_image_name }}:{{ fc_image_tag }}
{% if fc_image_tag in ['latest', 'stable'] %}
        imagePullPolicy: Always
{% else %}
        imagePullPolicy: IfNotPresent
{% endif %}
        # The default termination log (here for clarity)
        # But also fallback to stdout logs on error
        # if there is no termination log.
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: FallbackToLogsOnError
        env:
        - name: FRAGMENTOR_PLAY
          value: '{{ fc_play }}'
        - name: FRAGMENTOR_NAMESPACE
          value: '{{ fc_namespace }}'
        - name: AWS_ACCESS_KEY_ID
          value: '{{ aws_access_key_id }}'
        - name: AWS_SECRET_ACCESS_KEY
          value: '{{ aws_secret_access_key }}'
        # The number of seconds to 'sleep' keeping the Pod alive for inspection
        # once the Job is complete. Set to '0' to exit immediately.
        - name: KEEP_ALIVE_SECONDS
          value: '{{ fc_keep_alive_seconds }}'
{% if fc_image_tag in ['latest', 'stable'] %}
        # CICD_TRIGGER_ID is variable whose value is used to force
        # a redeployment of the underlying containers. This is used in
        # situations where the origin image's tag may not have changed
        # (e.g. it's 'latest' or 'stable') but a new build is expected to
        # be available. Without changing something in the container spec
        # a roll-out will not occur under these conditions.
        # Here we make sure something always changes!
        - name: CICD_TRIGGER_ID
          value: '{{ ansible_date_time.iso8601_micro }}'
{% endif %}
        resources:
          requests:
            cpu: {{ fc_cpu_request }}
            memory: {{ fc_mem_request }}
{% if fc_cpu_limit or fc_mem_limit %}
          limits:
{% if fc_cpu_limit %}
            cpu: {{ fc_cpu_limit }}
{% endif %}
{% if fc_mem_limit %}
            memory: {{ fc_mem_limit }}
{% endif %}
{% endif %}
        volumeMounts:
        - name: pgcopy
          mountPath: /pgcopy
        - name: work
          mountPath: /work
        - name: nextflow-config
          mountPath: /home/fragmentor/.nextflow/config
          subPath: config
        - name: parameters
          mountPath: /home/fragmentor/parameters.yaml
          subPath: parameters.yaml
        - name: kubeconfig
          mountPath: /home/fragmentor/.kube/config
          subPath: config

      volumes:
      - name: pgcopy
        persistentVolumeClaim:
          claimName: {{ fc_pgcopy_pvc_name }}
      - name: work
        persistentVolumeClaim:
          claimName: work
      - name: nextflow-config
        configMap:
          name: nextflow-config
      - name: parameters
        configMap:
          name: parameters
      - name: kubeconfig
        configMap:
          name: kubeconfig

      imagePullSecrets:
      - name: fragmentor

      restartPolicy: Never
